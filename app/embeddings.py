# app/embeddings.py
from openai import OpenAI
import os
from datetime import datetime

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# Contador global
embedding_counter = {"total": 0, "session_start": datetime.now()}

def embed_text(text: str) -> list:
    """
    Usa 1536 dimensiones - sweet spot de rendimiento/precisiÃ³n
    
    Beneficios:
    - 2x mÃ¡s rÃ¡pido que 3072
    - Solo ~1-2% menos preciso
    - Usa la mitad de almacenamiento
    - Perfecto para e-commerce con miles de productos
    """
    
    # Registrar inicio
    start_time = datetime.now()
    print(f"\n{'='*60}")
    print(f"ğŸ”„ Generando embedding #{embedding_counter['total'] + 1}")
    print(f"ğŸ“… Timestamp: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ“ Texto (primeros 100 chars): {text[:100]}...")
    print(f"{'='*60}")
    
    response = client.embeddings.create(
        model="text-embedding-3-large",
        input=text,
        dimensions=1536
    )
    
    # Registrar fin y estadÃ­sticas
    end_time = datetime.now()
    duration = (end_time - start_time).total_seconds()
    embedding_counter["total"] += 1
    
    print(f"âœ… Embedding generado exitosamente")
    print(f"â±ï¸  Tiempo de generaciÃ³n: {duration:.3f} segundos")
    print(f"ğŸ“Š Total embeddings en esta sesiÃ³n: {embedding_counter['total']}")
    print(f"ğŸ• Tiempo desde inicio: {(end_time - embedding_counter['session_start']).total_seconds():.1f}s")
    print(f"{'='*60}\n")
    
    return response.data[0].embedding

def get_embedding_stats():
    """Obtener estadÃ­sticas de embeddings"""
    return {
        "total": embedding_counter["total"],
        "session_start": embedding_counter["session_start"],
        "uptime": (datetime.now() - embedding_counter["session_start"]).total_seconds()
    }
